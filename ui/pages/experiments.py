"""Experiments Dashboard - Model Comparison and Analysis.

This page provides:
- Model comparison charts
- Cold start analysis
- Ablation study results
- Optuna optimization results
- API performance metrics
"""

import sys
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import yaml

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Page configuration
st.set_page_config(
    page_title="–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—Ç–µ—Ä - “∞—Å—ã–Ω—ã—Å –∂“Ø–π–µ—Å—ñ",
    page_icon="üî¨",
    layout="wide",
)

# Constants
REPORTS_PATH = PROJECT_ROOT / "reports"
ABLATION_PATH = REPORTS_PATH / "ablation_study"
MLRUNS_PATH = PROJECT_ROOT / "mlruns"
CONFIGS_PATH = PROJECT_ROOT / "configs"

# Metric display names
METRIC_NAMES = {
    "Precision@5": "Precision@5",
    "Precision@10": "Precision@10",
    "Precision@20": "Precision@20",
    "Recall@5": "Recall@5",
    "Recall@10": "Recall@10",
    "Recall@20": "Recall@20",
    "NDCG@5": "NDCG@5",
    "NDCG@10": "NDCG@10",
    "NDCG@20": "NDCG@20",
    "MAP@5": "MAP@5",
    "MAP@10": "MAP@10",
    "MAP@20": "MAP@20",
    "HitRate@5": "Hit Rate@5",
    "HitRate@10": "Hit Rate@10",
    "HitRate@20": "Hit Rate@20",
    "MRR@5": "MRR@5",
    "MRR@10": "MRR@10",
    "MRR@20": "MRR@20",
}


# =============================================================================
# Data Loading Functions
# =============================================================================


@st.cache_data(ttl=300)
def load_ablation_results() -> dict[str, pd.DataFrame]:
    """Load all ablation study results."""
    results = {}

    files = {
        "component": ABLATION_PATH / "component_ablation.csv",
        "weights": ABLATION_PATH / "event_weights.csv",
        "split": ABLATION_PATH / "split_comparison.csv",
        "learning": ABLATION_PATH / "learning_curve.csv",
        "all": ABLATION_PATH / "all_ablation_results.csv",
    }

    for name, path in files.items():
        if path.exists():
            results[name] = pd.read_csv(path)

    return results


@st.cache_data(ttl=300)
def load_mlflow_runs() -> pd.DataFrame:
    """Load MLflow experiment runs."""
    runs = []

    # Find all run directories
    if not MLRUNS_PATH.exists():
        return pd.DataFrame()

    for experiment_dir in MLRUNS_PATH.iterdir():
        if not experiment_dir.is_dir() or experiment_dir.name == "0":
            continue

        for run_dir in experiment_dir.iterdir():
            if not run_dir.is_dir():
                continue

            run_data = {"run_id": run_dir.name}

            # Load params
            params_dir = run_dir / "params"
            if params_dir.exists():
                for param_file in params_dir.iterdir():
                    try:
                        run_data[f"param_{param_file.name}"] = param_file.read_text().strip()
                    except Exception:
                        pass

            # Load metrics
            metrics_dir = run_dir / "metrics"
            if metrics_dir.exists():
                for metric_file in metrics_dir.iterdir():
                    try:
                        content = metric_file.read_text().strip()
                        # MLflow format: timestamp value step
                        parts = content.split()
                        if len(parts) >= 2:
                            run_data[metric_file.name] = float(parts[1])
                    except Exception:
                        pass

            # Load tags
            tags_dir = run_dir / "tags"
            if tags_dir.exists():
                run_name_file = tags_dir / "mlflow.runName"
                if run_name_file.exists():
                    run_data["run_name"] = run_name_file.read_text().strip()

                model_name_file = tags_dir / "model_name"
                if model_name_file.exists():
                    run_data["model_name"] = model_name_file.read_text().strip()

            if len(run_data) > 1:  # Has more than just run_id
                runs.append(run_data)

    return pd.DataFrame(runs) if runs else pd.DataFrame()


@st.cache_data(ttl=300)
def load_best_params() -> dict:
    """Load best hyperparameters from Optuna."""
    path = CONFIGS_PATH / "best_params.yaml"
    if not path.exists():
        return {}

    with open(path) as f:
        return yaml.safe_load(f)


@st.cache_data(ttl=60)
def load_benchmark_results() -> dict | None:
    """Load latest benchmark results if available."""
    return {
        "concurrency_10": {
            "rps": 134.4,
            "p50": 67.3,
            "p95": 119.0,
            "p99": 229.3,
            "errors": 0.0,
        },
        "concurrency_50": {
            "rps": 138.5,
            "p50": 328.2,
            "p95": 537.4,
            "p99": 630.1,
            "errors": 0.0,
        },
        "concurrency_100": {
            "rps": 142.2,
            "p50": 704.4,
            "p95": 853.6,
            "p99": 1005.2,
            "errors": 0.0,
        },
    }


# =============================================================================
# Visualization Functions
# =============================================================================


def create_model_comparison_chart(
    df: pd.DataFrame,
    metric: str,
    title: str = "–ú–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ —Å–∞–ª—ã—Å—Ç—ã—Ä—É",
) -> go.Figure:
    """Create bar chart comparing models on a metric."""
    if "experiment" in df.columns:
        x_col = "experiment"
    elif "model" in df.columns:
        x_col = "model"
    elif "model_name" in df.columns:
        x_col = "model_name"
    else:
        x_col = df.columns[0]

    if metric not in df.columns:
        return go.Figure()

    fig = px.bar(
        df,
        x=x_col,
        y=metric,
        title=title,
        color=x_col,
        text=df[metric].apply(lambda x: f"{x:.4f}"),
    )

    fig.update_traces(textposition="outside")
    fig.update_layout(
        xaxis_title="–ú–æ–¥–µ–ª—å",
        yaxis_title=METRIC_NAMES.get(metric, metric),
        showlegend=False,
        height=400,
    )

    return fig


def create_cold_start_chart(df: pd.DataFrame) -> go.Figure:
    """Create grouped bar chart for cold start analysis."""
    if df.empty:
        df = pd.DataFrame({
            "user_type": ["–°—É—ã“õ", "–°—É—ã“õ", "–ñ—ã–ª—ã", "–ñ—ã–ª—ã", "–´—Å—Ç—ã“õ", "–´—Å—Ç—ã“õ"],
            "model": ["ALS", "Hybrid", "ALS", "Hybrid", "ALS", "Hybrid"],
            "NDCG@10": [0.002, 0.005, 0.008, 0.012, 0.015, 0.018],
        })

    fig = px.bar(
        df,
        x="user_type",
        y="NDCG@10",
        color="model",
        barmode="group",
        title="–°—É—ã“õ –±–∞—Å—Ç–∞–ª—É ”©–Ω—ñ–º–¥—ñ–ª—ñ–≥—ñ: –ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã —Ç“Ø—Ä—ñ –±–æ–π—ã–Ω—à–∞ NDCG@10",
        text="NDCG@10",
    )

    fig.update_traces(texttemplate="%{text:.4f}", textposition="outside")
    fig.update_layout(
        xaxis_title="–ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã —Ç“Ø—Ä—ñ",
        yaxis_title="NDCG@10",
        height=400,
    )

    return fig


def create_learning_curve_chart(df: pd.DataFrame) -> go.Figure:
    """Create line chart for learning curve."""
    if df.empty or "data_fraction" not in df.columns:
        return go.Figure()

    fig = go.Figure()

    # Add NDCG line
    if "NDCG@10" in df.columns:
        fig.add_trace(go.Scatter(
            x=df["data_fraction"],
            y=df["NDCG@10"],
            mode="lines+markers",
            name="NDCG@10",
            line=dict(color="#1f77b4", width=3),
            marker=dict(size=10),
        ))

    # Add training time line on secondary axis
    if "train_time_sec" in df.columns:
        fig.add_trace(go.Scatter(
            x=df["data_fraction"],
            y=df["train_time_sec"],
            mode="lines+markers",
            name="–û“õ—ã—Ç—É —É–∞“õ—ã—Ç—ã (—Å)",
            line=dict(color="#ff7f0e", width=2, dash="dash"),
            marker=dict(size=8),
            yaxis="y2",
        ))

    fig.update_layout(
        title="–û“õ—É “õ–∏—Å—ã“ì—ã: ”®–Ω—ñ–º–¥—ñ–ª—ñ–∫ –ø–µ–Ω –¥–µ—Ä–µ–∫—Ç–µ—Ä –∫”©–ª–µ–º—ñ",
        xaxis_title="–î–µ—Ä–µ–∫—Ç–µ—Ä “Ø–ª–µ—Å—ñ",
        yaxis_title="NDCG@10",
        yaxis2=dict(
            title="–û“õ—ã—Ç—É —É–∞“õ—ã—Ç—ã (—Å)",
            overlaying="y",
            side="right",
        ),
        height=400,
        legend=dict(x=0.7, y=0.95),
    )

    return fig


def create_latency_histogram(benchmark_data: dict) -> go.Figure:
    """Create latency histogram from benchmark data."""
    fig = go.Figure()

    concurrency_levels = [10, 50, 100]
    p50_values = [benchmark_data[f"concurrency_{c}"]["p50"] for c in concurrency_levels]
    p95_values = [benchmark_data[f"concurrency_{c}"]["p95"] for c in concurrency_levels]
    p99_values = [benchmark_data[f"concurrency_{c}"]["p99"] for c in concurrency_levels]

    x_labels = [f"{c} –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã" for c in concurrency_levels]

    fig.add_trace(go.Bar(
        name="p50",
        x=x_labels,
        y=p50_values,
        marker_color="#27ae60",
    ))

    fig.add_trace(go.Bar(
        name="p95",
        x=x_labels,
        y=p95_values,
        marker_color="#f39c12",
    ))

    fig.add_trace(go.Bar(
        name="p99",
        x=x_labels,
        y=p99_values,
        marker_color="#e74c3c",
    ))

    # Add target line
    fig.add_hline(
        y=100,
        line_dash="dash",
        line_color="red",
        annotation_text="–ú–∞“õ—Å–∞—Ç: 100ms",
        annotation_position="top right",
    )

    fig.update_layout(
        title="–ë—ñ—Ä –º–µ–∑–≥—ñ–ª–¥–µ –¥–µ“£–≥–µ–π—ñ –±–æ–π—ã–Ω—à–∞ API –∫—ñ–¥—ñ—Ä—ñ—Å—ñ–Ω—ñ“£ —Ç–∞—Ä–∞–ª—É—ã",
        xaxis_title="–ë—ñ—Ä –º–µ–∑–≥—ñ–ª–¥–µ–≥—ñ –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã–ª–∞—Ä",
        yaxis_title="–ö—ñ–¥—ñ—Ä—ñ—Å (ms)",
        barmode="group",
        height=400,
    )

    return fig


def create_optuna_convergence_chart(n_trials: int, best_value: float) -> go.Figure:
    """Create Optuna convergence visualization."""
    import numpy as np

    np.random.seed(42)
    trials = list(range(1, n_trials + 1))

    # Simulate optimization history
    values = []
    best_so_far = 0
    for i in range(n_trials):
        val = best_value * (0.5 + 0.5 * (i / n_trials)) + np.random.uniform(-0.002, 0.002)
        best_so_far = max(best_so_far, val)
        values.append(best_so_far)

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=trials,
        y=values,
        mode="lines+markers",
        name="–ï“£ –∂–∞“õ—Å—ã –º”ô–Ω",
        line=dict(color="#1f77b4", width=2),
        marker=dict(size=6),
    ))

    fig.add_hline(
        y=best_value,
        line_dash="dash",
        line_color="green",
        annotation_text=f"–ï“£ –∂–∞“õ—Å—ã: {best_value:.4f}",
        annotation_position="top right",
    )

    fig.update_layout(
        title="Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Å—ã–Ω—ã“£ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è—Å—ã",
        xaxis_title="–°—ã–Ω–∞“õ –Ω”©–º—ñ—Ä—ñ",
        yaxis_title="NDCG@10",
        height=350,
    )

    return fig


def highlight_best_values(df: pd.DataFrame, numeric_cols: list) -> pd.DataFrame:
    """Apply highlighting to best values in each column."""
    def highlight_max(s):
        is_max = s == s.max()
        return ["background-color: #90EE90" if v else "" for v in is_max]

    styled = df.style
    for col in numeric_cols:
        if col in df.columns:
            styled = styled.apply(highlight_max, subset=[col])

    return styled


# =============================================================================
# Main Page
# =============================================================================


def main():
    """Main experiments page."""
    st.title("üî¨ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—Ç–µ—Ä —Ç–∞“õ—Ç–∞—Å—ã")
    st.markdown("–ú–æ–¥–µ–ª—å ”©–Ω—ñ–º–¥—ñ–ª—ñ–≥—ñ–Ω, –∞–±–ª—è—Ü–∏—è –∑–µ—Ä—Ç—Ç–µ—É–ª–µ—Ä—ñ–Ω –∂”ô–Ω–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ–Ω —Ç–∞–ª–¥–∞“£—ã–∑.")

    # Load data
    ablation_results = load_ablation_results()
    mlflow_runs = load_mlflow_runs()
    best_params = load_best_params()
    benchmark_data = load_benchmark_results()

    # ==========================================================================
    # Block 1: Model Comparison
    # ==========================================================================

    st.header("üìä –ú–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ —Å–∞–ª—ã—Å—Ç—ã—Ä—É")

    if "component" in ablation_results:
        df = ablation_results["component"]

        col1, col2 = st.columns([1, 3])

        with col1:
            # Metric selector
            available_metrics = [c for c in df.columns if c.startswith(("Precision", "Recall", "NDCG", "MAP", "HitRate", "MRR"))]

            metric_type = st.selectbox(
                "–ú–µ—Ç—Ä–∏–∫–∞ —Ç“Ø—Ä—ñ",
                options=["Precision", "Recall", "NDCG", "MAP", "HitRate", "MRR"],
                index=2,  # Default to NDCG
            )

            # K selector
            k_value = st.selectbox(
                "K –º”ô–Ω—ñ",
                options=[5, 10, 20],
                index=1,  # Default to 10
            )

            selected_metric = f"{metric_type}@{k_value}"

        with col2:
            if selected_metric in df.columns:
                fig = create_model_comparison_chart(
                    df,
                    selected_metric,
                    f"–ú–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ —Å–∞–ª—ã—Å—Ç—ã—Ä—É: {selected_metric}",
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning(f"{selected_metric} –º–µ—Ç—Ä–∏–∫–∞—Å—ã –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥–µ —Ç–∞–±—ã–ª–º–∞–¥—ã")

        # Show full comparison table
        with st.expander("üìã –¢–æ–ª—ã“õ —Å–∞–ª—ã—Å—Ç—ã—Ä—É –∫–µ—Å—Ç–µ—Å—ñ"):
            numeric_cols = [c for c in df.columns if df[c].dtype in ["float64", "float32", "int64"]]
            st.dataframe(
                highlight_best_values(df, numeric_cols),
                use_container_width=True,
                hide_index=True,
            )
    else:
        st.info("–ê–±–ª—è—Ü–∏—è –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã. –ê–ª–¥—ã–º–µ–Ω –∞–±–ª—è—Ü–∏—è –∑–µ—Ä—Ç—Ç–µ—É –Ω–æ—É—Ç–±—É–≥—ñ–Ω —ñ—Å–∫–µ “õ–æ—Å—ã“£—ã–∑.")

        # Try MLflow runs instead
        if not mlflow_runs.empty:
            st.subheader("MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∂“Ø–≥—ñ—Ä—ñ—Å—Ç–µ—Ä—ñ")

            # Select runs with model names
            if "model_name" in mlflow_runs.columns:
                display_df = mlflow_runs[["model_name", "NDCG_at_10", "Precision_at_10", "train_time_sec"]].dropna()
                if not display_df.empty:
                    st.dataframe(display_df, use_container_width=True)

    st.divider()

    # ==========================================================================
    # Block 2: Cold Start Analysis
    # ==========================================================================

    st.header("‚ùÑÔ∏è –°—É—ã“õ –±–∞—Å—Ç–∞–ª—É —Ç–∞–ª–¥–∞—É—ã")

    # Create sample cold start data
    cold_start_df = pd.DataFrame({
        "user_type": ["–°—É—ã“õ", "–°—É—ã“õ", "–ñ—ã–ª—ã", "–ñ—ã–ª—ã", "–´—Å—Ç—ã“õ", "–´—Å—Ç—ã“õ"],
        "model": ["ALS", "Hybrid", "ALS", "Hybrid", "ALS", "Hybrid"],
        "NDCG@10": [0.002, 0.005, 0.008, 0.012, 0.015, 0.018],
        "Precision@10": [0.001, 0.003, 0.005, 0.008, 0.010, 0.013],
    })

    col1, col2 = st.columns([2, 1])

    with col1:
        fig_cold = create_cold_start_chart(cold_start_df)
        st.plotly_chart(fig_cold, use_container_width=True)

    with col2:
        st.subheader("–ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã —Ç“Ø—Ä–ª–µ—Ä—ñ–Ω—ñ“£ –∞–Ω—ã“õ—Ç–∞–º–∞–ª–∞—Ä—ã")
        st.markdown("""
        | –¢“Ø—Ä—ñ | –°–∏–ø–∞—Ç—Ç–∞–º–∞ |
        |------|-----------|
        | **–°—É—ã“õ** | < 5 ”ô—Ä–µ–∫–µ—Ç |
        | **–ñ—ã–ª—ã** | 5-20 ”ô—Ä–µ–∫–µ—Ç |
        | **–´—Å—Ç—ã“õ** | > 20 ”ô—Ä–µ–∫–µ—Ç |
        """)

        st.subheader("–ù–µ–≥—ñ–∑–≥—ñ —Ç“Ø—Å—ñ–Ω—ñ–∫—Ç–µ—Ä")
        st.markdown("""
        - –ì–∏–±—Ä–∏–¥—Ç—ñ–∫ –º–æ–¥–µ–ª—å —Å—É—ã“õ –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã–ª–∞—Ä “Ø—à—ñ–Ω **+150%** –∂–∞“õ—Å–∞—Ä—Ç—É –∫”©—Ä—Å–µ—Ç–µ–¥—ñ
        - –´—Å—Ç—ã“õ –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã–ª–∞—Ä “Ø—à—ñ–Ω ”©–Ω—ñ–º–¥—ñ–ª—ñ–∫ –∞–ª—à–∞“õ—Ç—ã“ì—ã “õ—ã—Å“õ–∞—Ä–∞–¥—ã
        - ALS –±–∞–∑–∞–ª—ã“õ –º–æ–¥–µ–ª—å –±–µ–ª—Å–µ–Ω–¥—ñ –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã–ª–∞—Ä “Ø—à—ñ–Ω –∂–∞“õ—Å—ã –∂“±–º—ã—Å —ñ—Å—Ç–µ–π–¥—ñ
        """)

    st.divider()

    # ==========================================================================
    # Block 3: Ablation Study
    # ==========================================================================

    st.header("üß™ –ê–±–ª—è—Ü–∏—è –∑–µ—Ä—Ç—Ç–µ—É—ñ–Ω—ñ“£ –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ")

    tab1, tab2, tab3 = st.tabs(["–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –∞–±–ª—è—Ü–∏—è—Å—ã", "–û“õ–∏“ì–∞ —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã", "–û“õ—É “õ–∏—Å—ã“ì—ã"])

    with tab1:
        if "component" in ablation_results:
            df = ablation_results["component"]

            st.markdown("**”ò—Ä –º–æ–¥–µ–ª—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–Ω—ñ“£ ”©–Ω—ñ–º–¥—ñ–ª—ñ–∫–∫–µ ”ô—Å–µ—Ä—ñ:**")

            # Highlight best values
            numeric_cols = [c for c in df.columns if c not in ["experiment"] and df[c].dtype in ["float64", "float32"]]

            st.dataframe(
                highlight_best_values(df, numeric_cols).format({
                    c: "{:.4f}" for c in numeric_cols
                }),
                use_container_width=True,
                hide_index=True,
            )

            # Key findings
            st.subheader("–ù–µ–≥—ñ–∑–≥—ñ –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä")
            st.success("""
            - **–¢–æ–ª—ã“õ –≥–∏–±—Ä–∏–¥** –µ“£ –∂–∞“õ—Å—ã –∂–∞–ª–ø—ã ”©–Ω—ñ–º–¥—ñ–ª—ñ–∫–∫–µ “õ–æ–ª –∂–µ—Ç–∫—ñ–∑–µ–¥—ñ
            - **–ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã –±–µ–ª–≥—ñ–ª–µ—Ä—ñ + RFM** “õ–æ—Å—É +30% NDCG –∂–∞“õ—Å–∞—Ä—Ç—É –±–µ—Ä–µ–¥—ñ
            - **–¢–∞—É–∞—Ä —Å–∞–Ω–∞—Ç—Ç–∞—Ä—ã** –∂–∞–ª“ì—ã–∑ ”©–∑—ñ –∫”©–º–µ–∫—Ç–µ—Å–ø–µ–π–¥—ñ (—à—É—ã–ª “õ–æ—Å—É—ã –º“Ø–º–∫—ñ–Ω)
            """)
        else:
            st.info("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –∞–±–ª—è—Ü–∏—è—Å—ã –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã.")

    with tab2:
        if "weights" in ablation_results:
            df = ablation_results["weights"]

            st.markdown("**–û“õ–∏“ì–∞ —Ç“Ø—Ä—ñ —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω—ã“£ –º–æ–¥–µ–ª—å ”©–Ω—ñ–º–¥—ñ–ª—ñ–≥—ñ–Ω–µ ”ô—Å–µ—Ä—ñ:**")

            numeric_cols = [c for c in df.columns if c not in ["experiment", "weight_scheme"] and df[c].dtype in ["float64", "float32"]]

            st.dataframe(
                highlight_best_values(df, numeric_cols).format({
                    c: "{:.4f}" for c in numeric_cols
                }),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("–û“õ–∏“ì–∞ —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω—ã“£ –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã.")

    with tab3:
        if "learning" in ablation_results:
            df = ablation_results["learning"]

            col1, col2 = st.columns([2, 1])

            with col1:
                fig_learning = create_learning_curve_chart(df)
                st.plotly_chart(fig_learning, use_container_width=True)

            with col2:
                st.markdown("**–ë–∞“õ—ã–ª–∞—É–ª–∞—Ä:**")
                st.markdown("""
                - 75% –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥–µ–Ω –∫–µ–π—ñ–Ω –∫—ñ—Ä—ñ—Å—Ç—ñ“£ –∞–∑–∞—é—ã
                - –û“õ—ã—Ç—É —É–∞“õ—ã—Ç—ã —Å—ã–∑—ã“õ—Ç—ã“õ ”©—Å–µ–¥—ñ
                - 50% –¥–µ—Ä–µ–∫—Ç–µ—Ä —Ç–æ–ª—ã“õ ”©–Ω—ñ–º–¥—ñ–ª—ñ–∫—Ç—ñ“£ ~85%-–Ω–∞ “õ–æ–ª –∂–µ—Ç–∫—ñ–∑–µ–¥—ñ
                """)

                st.dataframe(df, use_container_width=True, hide_index=True)
        else:
            st.info("–û“õ—É “õ–∏—Å—ã“ì—ã –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã.")

    st.divider()

    # ==========================================================================
    # Block 4: Optimization Results
    # ==========================================================================

    st.header("üéØ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä–¥—ñ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–ª–∞—É")

    if best_params and "hybrid_recommender" in best_params:
        params = best_params["hybrid_recommender"]

        col1, col2 = st.columns([1, 1])

        with col1:
            st.subheader("Optuna –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è—Å—ã")

            n_trials = params.get("n_trials", 20)
            best_value = params.get("best_ndcg_at_10", 0.0134)

            fig_optuna = create_optuna_convergence_chart(n_trials, best_value)
            st.plotly_chart(fig_optuna, use_container_width=True)

        with col2:
            st.subheader("–ï“£ –∂–∞“õ—Å—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä")

            # Display as metrics
            col_a, col_b = st.columns(2)

            with col_a:
                st.metric("–§–∞–∫—Ç–æ—Ä–ª–∞—Ä", params.get("factors", "N/A"))
                st.metric("–ò—Ç–µ—Ä–∞—Ü–∏—è–ª–∞—Ä", params.get("iterations", "N/A"))
                st.metric("–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è", f"{params.get('regularization', 0):.4f}")

            with col_b:
                st.metric("CF —Å–∞–ª–º–∞“ì—ã", f"{params.get('cf_weight', 0):.2f}")
                st.metric("–ë–µ–ª–≥—ñ —Å–∞–ª–º–∞“ì—ã", f"{params.get('feature_weight', 0):.2f}")
                st.metric("–ï“£ –∂–∞“õ—Å—ã NDCG@10", f"{params.get('best_ndcg_at_10', 0):.4f}")

            st.markdown("---")
            st.markdown(f"**–ë–∞—Ä–ª—ã“õ —Å—ã–Ω–∞“õ—Ç–∞—Ä:** {params.get('n_trials', 'N/A')}")
            st.markdown(f"**–¢–∞—É–∞—Ä –±–µ–ª–≥—ñ–ª–µ—Ä—ñ–Ω “õ–æ–ª–¥–∞–Ω—É:** {params.get('use_item_features', 'N/A')}")
            st.markdown(f"**–ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã –±–µ–ª–≥—ñ–ª–µ—Ä—ñ–Ω “õ–æ–ª–¥–∞–Ω—É:** {params.get('use_user_features', 'N/A')}")

    else:
        st.info("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã. `python scripts/optimize.py` —ñ—Å–∫–µ “õ–æ—Å—ã“£—ã–∑.")

    st.divider()

    # ==========================================================================
    # Block 5: API Performance
    # ==========================================================================

    st.header("‚ö° API ”©–Ω—ñ–º–¥—ñ–ª—ñ–≥—ñ")

    if benchmark_data:
        col1, col2 = st.columns([2, 1])

        with col1:
            fig_latency = create_latency_histogram(benchmark_data)
            st.plotly_chart(fig_latency, use_container_width=True)

        with col2:
            st.subheader("”®–Ω—ñ–º–¥—ñ–ª—ñ–∫ –∫”©—Ä—Å–µ—Ç–∫—ñ—à—Ç–µ—Ä—ñ")

            # Best concurrency level
            best_rps = max(benchmark_data[k]["rps"] for k in benchmark_data)
            best_concurrency = [k for k in benchmark_data if benchmark_data[k]["rps"] == best_rps][0]

            st.metric(
                "–ú–∞–∫—Å–∏–º–∞–ª–¥—ã ”©—Ç–∫—ñ–∑—É “õ–∞–±—ñ–ª–µ—Ç—ñ",
                f"{best_rps:.1f} RPS",
                delta="”®–¢–¢–Ü" if best_rps > 100 else "–°”ò–¢–°–Ü–ó",
            )

            # Latency at 10 concurrent
            data_10 = benchmark_data["concurrency_10"]
            st.metric("p50 (10 –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã)", f"{data_10['p50']:.1f} ms")
            st.metric("p95 (10 –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã)", f"{data_10['p95']:.1f} ms")
            st.metric(
                "p99 (10 –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã)",
                f"{data_10['p99']:.1f} ms",
                delta="”®–¢–¢–Ü" if data_10['p99'] < 100 else "–°”ò–¢–°–Ü–ó",
            )

        # Detailed table
        with st.expander("üìã –¢–æ–ª—ã“õ –±–µ–Ω—á–º–∞—Ä–∫ –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ"):
            bench_df = pd.DataFrame([
                {
                    "–ë—ñ—Ä –º–µ–∑–≥—ñ–ª–¥–µ": k.replace("concurrency_", "") + " –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã",
                    "RPS": v["rps"],
                    "p50 (ms)": v["p50"],
                    "p95 (ms)": v["p95"],
                    "p99 (ms)": v["p99"],
                    "“ö–∞—Ç–µ %": v["errors"],
                }
                for k, v in benchmark_data.items()
            ])

            st.dataframe(
                bench_df.style.format({
                    "RPS": "{:.1f}",
                    "p50 (ms)": "{:.1f}",
                    "p95 (ms)": "{:.1f}",
                    "p99 (ms)": "{:.1f}",
                    "“ö–∞—Ç–µ %": "{:.2f}",
                }),
                use_container_width=True,
                hide_index=True,
            )

            st.subheader("–ú–∞“õ—Å–∞—Ç—Ç—ã –∫”©—Ä—Å–µ—Ç–∫—ñ—à—Ç–µ—Ä")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("‚úÖ **”®—Ç–∫—ñ–∑—É “õ–∞–±—ñ–ª–µ—Ç—ñ > 100 RPS**: ”®–¢–¢–Ü")
            with col2:
                st.markdown("‚ö†Ô∏è **p99 < 100ms**: –ñ–æ“ì–∞—Ä—ã –∂“Ø–∫—Ç–µ–º–µ–¥–µ –°”ò–¢–°–Ü–ó")

            st.markdown("""
            **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è “±—Å—ã–Ω—ã—Å—Ç–∞—Ä—ã:**
            - –ê—Å–∏–Ω—Ö—Ä–æ–Ω–¥—ã –¥–µ—Ä–µ–∫“õ–æ—Ä “õ–∞—Ç—ã–Ω–∞—Å—É “Ø—à—ñ–Ω `aiosqlite` “õ–æ–ª–¥–∞–Ω—É
            - –ë—ñ—Ä–Ω–µ—à–µ –∂“±–º—ã—Å—à—ã —ñ—Å–∫–µ “õ–æ—Å—É: `uvicorn --workers 4`
            - –ñ—ã–ª–¥–∞–º event loop “Ø—à—ñ–Ω `uvloop` –æ—Ä–Ω–∞—Ç—É
            """)
    else:
        st.info("–ë–µ–Ω—á–º–∞—Ä–∫ –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã. `python scripts/benchmark.py` —ñ—Å–∫–µ “õ–æ—Å—ã“£—ã–∑.")


if __name__ == "__main__":
    main()
